{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values in train labels: 0\n",
      "NaN values in test labels: 0\n",
      "Data types in train_df:\n",
      "Packet Count                    int64\n",
      "Total Length                    int64\n",
      "Avg Interval (s)              float64\n",
      "Max Interval (s)              float64\n",
      "Min Interval (s)              float64\n",
      "Avg Length (bytes)            float64\n",
      "Max Length (bytes)              int64\n",
      "Min Length (bytes)              int64\n",
      "Most Common Length (bytes)      int64\n",
      "Label                           int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# Create label mapping\n",
    "label_mapping = {\n",
    "    'ChatGPT': 0,\n",
    "    'Reddit': 1,\n",
    "    'Wikipedia': 2,\n",
    "    'LinkedIn': 3\n",
    "}\n",
    "\n",
    "# Convert label column using mapping\n",
    "train_df.iloc[:, -1] = train_df.iloc[:, -1].map(label_mapping)\n",
    "test_df.iloc[:, -1] = test_df.iloc[:, -1].map(label_mapping)\n",
    "\n",
    "# Check for any NaN values in labels \n",
    "print(f\"NaN values in train labels: {train_df.iloc[:, -1].isna().sum()}\")\n",
    "print(f\"NaN values in test labels: {test_df.iloc[:, -1].isna().sum()}\")\n",
    "\n",
    "# Convert feature columns to numeric and handle NaN values\n",
    "for col in train_df.columns[:-1]:  # exclude label column\n",
    "    train_df[col] = pd.to_numeric(train_df[col], errors='coerce')\n",
    "    test_df[col] = pd.to_numeric(test_df[col], errors='coerce')\n",
    "\n",
    "# Fill NaN values with column means instead of dropping rows\n",
    "train_df = train_df.fillna(train_df.mean())\n",
    "test_df = test_df.fillna(test_df.mean())\n",
    "\n",
    "# Verify data types before conversion to tensors\n",
    "print(f\"Data types in train_df:\\n{train_df.dtypes}\")\n",
    "\n",
    "# Force convert to int64\n",
    "train_df.iloc[:, -1] = train_df.iloc[:, -1].astype('int64')\n",
    "test_df.iloc[:, -1] = test_df.iloc[:, -1].astype('int64')\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.features = dataframe.iloc[:, :-1].values.astype(np.float32)\n",
    "        self.labels = dataframe.iloc[:, -1].values.astype(np.int64)\n",
    "        \n",
    "        self.features = torch.tensor(self.features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(self.labels, dtype=torch.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx].unsqueeze(0), self.labels[idx]\n",
    "        \n",
    "\n",
    "# Create datasets and data loaders\n",
    "train_dataset = CustomDataset(train_df)\n",
    "test_dataset = CustomDataset(test_df)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss: 1.4081\n",
      "Epoch [2/30], Loss: 1.3972\n",
      "Epoch [3/30], Loss: 1.3461\n",
      "Epoch [4/30], Loss: 1.3495\n",
      "Epoch [5/30], Loss: 1.3420\n",
      "Epoch [6/30], Loss: 1.3411\n",
      "Epoch [7/30], Loss: 1.3300\n",
      "Epoch [8/30], Loss: 1.3521\n",
      "Epoch [9/30], Loss: 1.3338\n",
      "Epoch [10/30], Loss: 1.3075\n",
      "Epoch [11/30], Loss: 1.3239\n",
      "Epoch [12/30], Loss: 1.3138\n",
      "Epoch [13/30], Loss: 1.2763\n",
      "Epoch [14/30], Loss: 1.3004\n",
      "Epoch [15/30], Loss: 1.2647\n",
      "Epoch [16/30], Loss: 1.2762\n",
      "Epoch [17/30], Loss: 1.2797\n",
      "Epoch [18/30], Loss: 1.2713\n",
      "Epoch [19/30], Loss: 1.2239\n",
      "Epoch [20/30], Loss: 1.2198\n",
      "Epoch [21/30], Loss: 1.2447\n",
      "Epoch [22/30], Loss: 1.2829\n",
      "Epoch [23/30], Loss: 1.2393\n",
      "Epoch [24/30], Loss: 1.2496\n",
      "Epoch [25/30], Loss: 1.2241\n",
      "Epoch [26/30], Loss: 1.2553\n",
      "Epoch [27/30], Loss: 1.2178\n",
      "Epoch [28/30], Loss: 1.2216\n",
      "Epoch [29/30], Loss: 1.2251\n",
      "Epoch [30/30], Loss: 1.1908\n",
      "Test Accuracy: 54.55%\n"
     ]
    }
   ],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "\n",
    "            nn.Conv1d(32, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "\n",
    "            nn.Conv1d(64, 128, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128 * 9, 256),  # 128 channels, 9 features\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 4)   # since you have 4 classes (ChatGPT, reddit, wiki, linkedin)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = CNNModel().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)  # your learning rate\n",
    "\n",
    "\n",
    "num_epochs = 30\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Testing\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
